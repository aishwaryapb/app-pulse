# AppPulse

A comprehensive full-stack monitoring platform with AI-powered insights, built for real-time application health tracking and intelligent performance analysis.

## Overview

AppPulse is an advanced monitoring solution that combines real-time event streaming, comprehensive metrics collection, and AI-powered insights to provide developers with deep visibility into their application's health and performance. It features dual user interfaces and an intelligent AI assistant powered by Google Gemini and Model Context Protocol (MCP).

## Architecture

![architecture](images/architecture.png "Architecture")

### Core Components

- **Backend Service** - Python FastAPI with comprehensive API patterns and AI integration
- **Web Application** - Next.js frontend with TypeScript and role-based interfaces
- **Event Streaming** - Apache Kafka for real-time metrics processing and data flow
- **AI Assistant** - Google Gemini LLM with MCP server for intelligent metrics analysis
- **Data Layer** - Hybrid storage with in-memory real-time data and SQLite persistence

### API Endpoints

- `/api/v1/*` - CRUD operations with automatic metrics collection
- `/api/log/*` - Logging, metrics, and dashboard data endpoints
- `/api/chat/*` - AI assistant chat interface with metrics integration

## Features

### ğŸ¤– AI-Powered Insights

- **Intelligent Chat Assistant** - Ask questions about your metrics in plain English
- **Real-time Analysis** - AI analyzes live data to provide actionable insights
- **Performance Recommendations** - Smart suggestions for optimization and issue resolution
- **Natural Language Queries** - "How is my API performing?" gets real metrics-based answers

### ğŸ”§ For Developers

- **Real-time Metrics Dashboard** - Live widgets showing API performance, system health, and errors
- **Comprehensive Monitoring** - API response times, success rates, system resources, and error tracking
- **Interactive Logs Viewer** - Filterable logs with API and UI error separation
- **Performance Trends** - Identify bottlenecks and slow endpoints
- **Test Error Generation** - Built-in tools to test error handling and monitoring

### ğŸ‘¥ For Users

- **CRUD Application Interface** - Full-featured item management with real-time persistence
- **Seamless User Experience** - Clean, responsive interface with automatic error reporting
- **Real-time Data Management** - Create, read, update, delete operations with immediate feedback

### ğŸ“Š Advanced Monitoring

- **Hybrid Data Storage** - In-memory for real-time dashboards, SQLite for historical analysis
- **Automatic Error Capture** - Frontend JavaScript errors and API failures automatically logged
- **System Health Tracking** - CPU, memory, and disk usage monitoring with periodic updates
- **Event Streaming** - All metrics flow through Kafka for scalable, real-time processing

## Technology Stack

- **Backend**: Python FastAPI, Pydantic, SQLAlchemy, FastMCP
- **Frontend**: Next.js 14, TypeScript, SCSS, React Hooks
- **AI & MCP**: Google Gemini AI, FastMCP 2.0, Model Context Protocol
- **Streaming**: Apache Kafka with custom consumer/producer services
- **Database**: SQLite with async support and time-series optimization
- **Containerization**: Docker & Docker Compose for Kafka infrastructure
- **Monitoring**: Custom middleware, automatic error capture, real-time metrics collection

## Quick Start

### Prerequisites

- Docker and Docker Compose installed
- Node.js 18+ (for local development)
- Python 3.11+ (for local development)
- Google AI API Key (for AI assistant features)

### Installation

1. **Clone the repository**

   ```bash
   git clone <repository-url>
   cd apppulse
   ```

2. **Environment Setup**

   ```bash
   cp .env.example .env
   # Edit .env with your configuration:
   # - GOOGLE_API_KEY=your_google_ai_api_key
   # - AI_PROVIDER=gemini
   # - KAFKA_BOOTSTRAP_SERVERS=localhost:9092
   ```

3. **Start Kafka Infrastructure**

   ```bash
   docker-compose up -d
   ```

4. **Backend Setup**

   ```bash
   cd backend
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   uvicorn app.main:app --reload --port 8000
   ```

5. **Frontend Setup**

   ```bash
   cd frontend
   npm install
   npm run dev
   ```

6. **Access the Application**
   - Web App: http://localhost:3000
   - Backend API: http://localhost:8000
   - Kafka UI: http://localhost:8080
   - API Documentation: http://localhost:8000/docs

## Project Structure

```
apppulse/
â”œâ”€â”€ backend/                    # FastAPI backend service
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py            # Application entry point
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration management
â”‚   â”‚   â”œâ”€â”€ routers/           # API route handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ v1/            # CRUD operations with metrics
â”‚   â”‚   â”‚   â”œâ”€â”€ log/           # Logging and dashboard APIs
â”‚   â”‚   â”‚   â””â”€â”€ chat.py        # AI assistant chat API
â”‚   â”‚   â”œâ”€â”€ services/          # Business logic services
â”‚   â”‚   â”‚   â”œâ”€â”€ kafka_service.py        # Kafka producer
â”‚   â”‚   â”‚   â”œâ”€â”€ kafka_consumer.py       # Kafka consumer
â”‚   â”‚   â”‚   â”œâ”€â”€ message_handler.py      # Message processing
â”‚   â”‚   â”‚   â”œâ”€â”€ memory_storage.py       # In-memory metrics
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics_service.py      # Metrics collection
â”‚   â”‚   â”‚   â””â”€â”€ chat_service.py         # AI chat integration
â”‚   â”‚   â”œâ”€â”€ middleware/        # Request/response middleware
â”‚   â”‚   â”‚   â””â”€â”€ metrics_middleware.py   # Auto metrics collection
â”‚   â”‚   â”œâ”€â”€ models/            # Data models and schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py    # SQLAlchemy models
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py     # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ database/          # Database configuration
â”‚   â”‚   â”‚   â””â”€â”€ connection.py  # SQLite setup
â”‚   â”‚   â””â”€â”€ mcp/               # Model Context Protocol
â”‚   â”‚       â””â”€â”€ metrics_server.py      # MCP tools for AI
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â””â”€â”€ Dockerfile            # Docker configuration
â”œâ”€â”€ frontend/                  # Next.js frontend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx       # Home page with persona selection
â”‚   â”‚   â”‚   â”œâ”€â”€ user/          # User persona (CRUD interface)
â”‚   â”‚   â”‚   â””â”€â”€ developer/     # Developer persona (monitoring)
â”‚   â”‚   â”‚       â”œâ”€â”€ page.tsx   # Main developer dashboard
â”‚   â”‚   â”‚       â””â”€â”€ components/
â”‚   â”‚   â”‚           â”œâ”€â”€ Dashboard.tsx  # Metrics widgets
â”‚   â”‚   â”‚           â”œâ”€â”€ Logs.tsx       # Log viewer
â”‚   â”‚   â”‚           â””â”€â”€ Chat.tsx       # AI assistant
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts         # API client configuration
â”‚   â”‚   â”‚   â””â”€â”€ errorLogger.ts # Automatic error capture
â”‚   â”‚   â””â”€â”€ types/
â”‚   â”‚       â””â”€â”€ index.ts       # TypeScript definitions
â”‚   â”œâ”€â”€ package.json          # Node.js dependencies
â”‚   â””â”€â”€ next.config.js        # Next.js configuration
â”œâ”€â”€ kafka/                    # Kafka configuration
â”‚   â””â”€â”€ topics/
â”‚       â””â”€â”€ create-topics.sh  # Topic initialization script
â”œâ”€â”€ data/                     # SQLite database storage
â”‚   â””â”€â”€ apppulse.db          # Application database
â”œâ”€â”€ docker-compose.yml        # Kafka infrastructure
â”œâ”€â”€ .env                      # Environment configuration
â””â”€â”€ README.md                 # Project documentation
```

## Monitoring Capabilities

### Real-time Metrics Collection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Request   â”‚â”€â”€â”€â–¶â”‚  Middleware     â”‚â”€â”€â”€â–¶â”‚  Kafka Topics   â”‚
â”‚   (Automatic)   â”‚    â”‚  Collection     â”‚    â”‚  (Event Stream) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dashboard     â”‚â—„â”€â”€â”€â”‚  In-Memory      â”‚â—„â”€â”€â”€â”‚  Kafka Consumer â”‚
â”‚   (Real-time)   â”‚    â”‚  Storage        â”‚    â”‚  (Processing)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Historical     â”‚â—„â”€â”€â”€â”‚  Database       â”‚
                       â”‚  Analysis       â”‚    â”‚  (SQLite)       â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Collected Metrics

#### Backend Metrics

- **API Performance**: Request/response times, throughput, success rates
- **System Resources**: CPU usage, memory consumption, disk utilization
- **Error Tracking**: API failures, exception details, error patterns
- **Custom Events**: Business logic events, user actions, system events

#### Frontend Metrics

- **Error Monitoring**: JavaScript errors, unhandled exceptions, promise rejections
- **User Interactions**: Click events, form submissions, navigation patterns
- **Performance**: Page load times, component render times, client-side metrics
- **Custom Events**: Application-specific user behavior and business events

### AI-Powered Analysis

#### Model Context Protocol (MCP) Integration

The AI assistant uses MCP to access real-time metrics through specialized tools:

- `get_api_metrics_summary()` - Comprehensive API performance analysis
- `get_system_metrics_summary()` - System health and resource utilization
- `get_error_analysis()` - Error patterns and failure analysis
- `get_performance_trends()` - Performance bottlenecks and optimization insights

#### Natural Language Queries

Ask questions like:

- _"How is my API performing today?"_
- _"Are there any concerning error patterns?"_
- _"Which endpoints are causing performance issues?"_
- _"What's the overall health of my system?"_
- _"Show me recent error trends and their impact"_

## API Documentation

### REST API Endpoints

#### CRUD Operations (`/api/v1/*`)

```http
GET    /api/v1/items           # List all items
POST   /api/v1/items           # Create new item
GET    /api/v1/items/{id}      # Get specific item
PUT    /api/v1/items/{id}      # Update item
DELETE /api/v1/items/{id}      # Delete item
```

#### Monitoring & Logging (`/api/log/*`)

```http
GET    /api/log/dashboard-data # Real-time dashboard metrics
POST   /api/log/errors         # Log UI errors
POST   /api/log/system-metrics # Trigger system metrics collection
GET    /api/log/api-logs       # Retrieve API error logs
GET    /api/log/ui-logs        # Retrieve UI error logs
```

#### AI Assistant (`/api/chat/*`)

```http
POST   /api/chat/chat          # Chat with AI assistant
```

**Example Chat Request:**

```json
{
  "message": "How is my API performing today?",
  "conversation_history": [
    { "role": "user", "content": "Previous question" },
    { "role": "assistant", "content": "Previous response" }
  ]
}
```

### Interactive Documentation

Once running, visit:

- **Swagger UI**: http://localhost:8000/docs

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

**Built with ğŸ©µ using modern web technologies and Claude Code**

_AppPulse - Intelligent monitoring for the modern web_
